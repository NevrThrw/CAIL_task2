{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import json\n",
    "\n",
    "divorce_model=Doc2Vec.load(\"../divorce/divorce.model\") #divorce的Doc2Vec模型\n",
    "loan_model=Doc2Vec.load(\"../loan/loan.model\")#loan的Doc2Vec模型\n",
    "labor_model=Doc2Vec.load(\"../labor/labor.model\")#labor的Doc2Vec模型\n",
    "\n",
    "threshold=0.2\n",
    "test_ratio = 0.3\n",
    "punction = \"！？。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\"\n",
    "\n",
    "\n",
    "\n",
    "def content_process(content):\n",
    "    text = re.sub(r'[{}]'.format(punction),' ',content).split(' ')\n",
    "    sent=[]\n",
    "    for sub_sentence in text:\n",
    "        if sub_sentence!='':\n",
    "            sent.extend(list(jieba.cut(sub_sentence)))\n",
    "    return sent\n",
    "\n",
    "def splitDataSet(X,Y,modify=False,ratio=test_ratio): #构建训练集和测试集\n",
    "    if modify: #调整正负样本比例\n",
    "        X_true=[]\n",
    "        X_false=[]\n",
    "        Y_true=[]\n",
    "        Y_false=[]\n",
    "        for i in range(len(Y)):\n",
    "            if Y[i]==1:\n",
    "                X_true.append(X[i])\n",
    "                Y_true.append(Y[i])\n",
    "            else:\n",
    "                X_false.append(X[i])\n",
    "                Y_false.append(Y[i])\n",
    "        true_num = len(X_true)\n",
    "        false_num = true_num*ration\n",
    "        for i in range(0,len(X_false),int(len(X_false)/false_num)):\n",
    "            X_true.append(X_false[i])\n",
    "            Y_true.append(Y_false[i])\n",
    "        X_train,X_test,Y_train,Y_test =  train_test_split(X_true,Y_true,test_size=test_ratio,shuffle=True)\n",
    "    else:\n",
    "        X_train,X_test,Y_train,Y_test =  train_test_split(X,Y,test_size=test_ratio,shuffle=True)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "\n",
    "def transferTagVec(tag_dict,tags):\n",
    "    tagVec=[]\n",
    "    for key,val in tag_dict.items():\n",
    "        if key in tags:\n",
    "            tagVec.append(1)\n",
    "        else:\n",
    "            tagVec.append(0)\n",
    "    return tagVec\n",
    "\n",
    "def reverseTagVec(tag_dict,tagVec):\n",
    "    tags=[]\n",
    "    keys=list(tag_dict.keys())\n",
    "    for i in range(len(keys)):\n",
    "        if tagVec[i]==1:\n",
    "            tags.append(keys[i])\n",
    "    return tags\n",
    "\n",
    "def trainCC(d2vModel,modelPath,tag_path,input_path):\n",
    "    print(\"Initializing data loader\")\n",
    "    loader = DataLoader(input_path,tag_path)\n",
    "    label_size = loader.tag_cnt\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    print(\"Loading data into data loader\")\n",
    "    for content in loader.data:\n",
    "        for sub_con in content:\n",
    "            text = sub_con['sentence']\n",
    "            tags = sub_con['labels']\n",
    "            text = content_process(text)\n",
    "            X.append(d2vModel.infer_vector(text))\n",
    "            Y.append(transferTagVec(loader.tag_dict,tags))\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    base_classifier=LogisticRegression(solver='lbfgs')\n",
    "    chains = [ClassifierChain(base_classifier,order='random',random_state=j) for j in range(label_size)]\n",
    "    cnt=1\n",
    "    for chain in chains:\n",
    "        chain.fit(X,Y)\n",
    "        print(\"ClassifierChain \"+str(cnt)+\" train finish\")\n",
    "        cnt+=1\n",
    "    cnt=1\n",
    "    for model in chains:\n",
    "        joblib.dump(model,modelPath+str(cnt)+'.model')\n",
    "        cnt+=1\n",
    "    print(\"Train process finish\")\n",
    "    \n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self,file_path,tag_path=None):\n",
    "        self.data=[]\n",
    "        with open(file_path,'r',encoding='utf-8') as f: # read training or testing data\n",
    "            for line in f.readlines():\n",
    "                doc = json.loads(line)\n",
    "                self.data.append(doc)\n",
    "        self.tag_dict={}\n",
    "        self.tag_cnt=0;\n",
    "        if tag_path:\n",
    "            with open(tag_path,'r',encoding='utf-8') as f: # read data tag file if tag_path passed\n",
    "                for line in f:\n",
    "                    self.tag_cnt+=1\n",
    "                    self.tag_dict[line.strip()]=self.tag_cnt\n",
    "                    \n",
    "class DataWriter:\n",
    "    def __init__(self,out_path):\n",
    "        self.out_content=[]\n",
    "        self.out_path=out_path\n",
    "        \n",
    "    def writeJson(self):\n",
    "        with open(self.out_path,'w',encoding='utf-8') as f:\n",
    "            for data in self.out_content:\n",
    "                json.dump(data,f,ensure_ascii=False)\n",
    "                f.write(\"\\n\")\n",
    "        f.close()\n",
    "                \n",
    "    def writeContent(self,content):\n",
    "        self.out_content.append(content)\n",
    "        \n",
    "        \n",
    "class CCPredictor:\n",
    "    def __init__(self,ccmodel_path,d2vmodel_path,tag_path):\n",
    "        self.models=[]\n",
    "        self.tag_cnt=0\n",
    "        self.tag_dict={}\n",
    "        with open(tag_path,'r',encoding='utf-8') as f: # read data tag file if tag_path passed\n",
    "                for line in f:\n",
    "                    self.tag_cnt+=1\n",
    "                    self.tag_dict[line.strip()]=self.tag_cnt\n",
    "                    \n",
    "        for i in range(1,self.tag_cnt+1):\n",
    "            path = ccmodel_path+str(i)+'.model'\n",
    "            self.models.append(joblib.load(path))\n",
    "        \n",
    "        self.d2v = Doc2Vec.load(d2vmodel_path)\n",
    "    \n",
    "    def predict(self,content):\n",
    "        content = content_process(content)\n",
    "        x = self.d2v.infer_vector(content)\n",
    "        chain_predict = np.array([chain.predict([x]) for chain in self.models])\n",
    "        predict_label = chain_predict.mean(axis=0)\n",
    "        for o in range(len(predict_label[0])):\n",
    "            predict_label[0][o]= 1 if predict_label[0][o]>threshold else 0\n",
    "        return reverseTagVec(self.tag_dict,predict_label[0])\n",
    "    \n",
    "    def predictData(self,data_writer,data_loader):\n",
    "        for content in data_loader.data:\n",
    "            data_line=[]\n",
    "            for sub_content in content:\n",
    "                sub_content['labels']= self.predict(sub_content['sentence'])\n",
    "                data_line.append(sub_content)\n",
    "            data_writer.writeContent(data_line)\n",
    "        data_writer.writeJson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\RPJ\\AppData\\Local\\Temp\\jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------labor------------------\n",
      "Initializing data loader\n",
      "Loading data into data loader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 1.072 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassifierChain 1 train finish\n",
      "ClassifierChain 2 train finish\n",
      "ClassifierChain 3 train finish\n",
      "ClassifierChain 4 train finish\n",
      "ClassifierChain 5 train finish\n",
      "ClassifierChain 6 train finish\n",
      "ClassifierChain 7 train finish\n",
      "ClassifierChain 8 train finish\n",
      "ClassifierChain 9 train finish\n",
      "ClassifierChain 10 train finish\n",
      "ClassifierChain 11 train finish\n",
      "ClassifierChain 12 train finish\n",
      "ClassifierChain 13 train finish\n",
      "ClassifierChain 14 train finish\n",
      "ClassifierChain 15 train finish\n",
      "ClassifierChain 16 train finish\n",
      "ClassifierChain 17 train finish\n",
      "ClassifierChain 18 train finish\n",
      "ClassifierChain 19 train finish\n",
      "ClassifierChain 20 train finish\n",
      "Train process finish\n",
      "-----------------loan------------------\n",
      "Initializing data loader\n",
      "Loading data into data loader\n",
      "ClassifierChain 1 train finish\n",
      "ClassifierChain 2 train finish\n",
      "ClassifierChain 3 train finish\n",
      "ClassifierChain 4 train finish\n",
      "ClassifierChain 5 train finish\n",
      "ClassifierChain 6 train finish\n",
      "ClassifierChain 7 train finish\n",
      "ClassifierChain 8 train finish\n",
      "ClassifierChain 9 train finish\n",
      "ClassifierChain 10 train finish\n",
      "ClassifierChain 11 train finish\n",
      "ClassifierChain 12 train finish\n",
      "ClassifierChain 13 train finish\n",
      "ClassifierChain 14 train finish\n",
      "ClassifierChain 15 train finish\n",
      "ClassifierChain 16 train finish\n",
      "ClassifierChain 17 train finish\n",
      "ClassifierChain 18 train finish\n",
      "ClassifierChain 19 train finish\n",
      "ClassifierChain 20 train finish\n",
      "Train process finish\n",
      "-----------------divorce------------------\n",
      "Initializing data loader\n",
      "Loading data into data loader\n",
      "ClassifierChain 1 train finish\n",
      "ClassifierChain 2 train finish\n",
      "ClassifierChain 3 train finish\n",
      "ClassifierChain 4 train finish\n",
      "ClassifierChain 5 train finish\n",
      "ClassifierChain 6 train finish\n",
      "ClassifierChain 7 train finish\n",
      "ClassifierChain 8 train finish\n",
      "ClassifierChain 9 train finish\n",
      "ClassifierChain 10 train finish\n",
      "ClassifierChain 11 train finish\n",
      "ClassifierChain 12 train finish\n",
      "ClassifierChain 13 train finish\n",
      "ClassifierChain 14 train finish\n",
      "ClassifierChain 15 train finish\n",
      "ClassifierChain 16 train finish\n",
      "ClassifierChain 17 train finish\n",
      "ClassifierChain 18 train finish\n",
      "ClassifierChain 19 train finish\n",
      "ClassifierChain 20 train finish\n",
      "Train process finish\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    train = True  #是否训练模型\n",
    "    \n",
    "    # ------------labor--------------------\n",
    "    print(\"-----------------labor------------------\")\n",
    "    if train:\n",
    "        trainCC(labor_model,\"../model/ClassifierChain/labor/\",\"../labor/tags.txt\",\"../labor/train_selected.json\")\n",
    "    predictor = CCPredictor(\"../model/ClassifierChain/labor/\",\"../labor/labor.model\",\"../labor/tags.txt\")\n",
    "    writer = DataWriter(\"../output/ClassifierChain/labor/output.json\")\n",
    "    loader = DataLoader(\"../labor/data_small_selected.json\")\n",
    "    predictor.predictData(writer,loader)\n",
    "\n",
    "\n",
    "\n",
    "    # ------------loan---------------------\n",
    "    print(\"-----------------loan------------------\")\n",
    "    if train:\n",
    "        trainCC(labor_model,\"../model/ClassifierChain/loan/\",\"../loan/tags.txt\",\"../loan/train_selected.json\")\n",
    "    predictor = CCPredictor(\"../model/ClassifierChain/loan/\",\"../loan/loan.model\",\"../loan/tags.txt\")\n",
    "    writer = DataWriter(\"../output/ClassifierChain/loan/output.json\")\n",
    "    loader = DataLoader(\"../loan/data_small_selected.json\")\n",
    "    predictor.predictData(writer,loader)\n",
    "\n",
    "\n",
    "\n",
    "    # ------------divorce-------------------\n",
    "    print(\"-----------------divorce------------------\")\n",
    "    if train:\n",
    "        trainCC(labor_model,\"../model/ClassifierChain/divorce/\",\"../divorce/tags.txt\",\"../divorce/train_selected.json\")\n",
    "    predictor = CCPredictor(\"../model/ClassifierChain/divorce/\",\"../divorce/divorce.model\",\"../divorce/tags.txt\")\n",
    "    writer = DataWriter(\"../output/ClassifierChain/divorce/output.json\")\n",
    "    loader = DataLoader(\"../divorce/data_small_selected.json\")\n",
    "    predictor.predictData(writer,loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
