{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class Judger:\n",
    "    # Initialize Judger, with the path of tag list\n",
    "    def __init__(self, tag_path):\n",
    "        self.tag_dic = {}\n",
    "        f = open(tag_path, \"r\", encoding='utf-8')\n",
    "        self.task_cnt = 0\n",
    "        for line in f:\n",
    "            self.task_cnt += 1\n",
    "            self.tag_dic[line[:-1]] = self.task_cnt\n",
    "\n",
    "    # Format the result generated by the Predictor class\n",
    "    @staticmethod\n",
    "    def format_result(result):\n",
    "        rex = {\"tags\": []}\n",
    "        res_art = []\n",
    "        for x in result[\"tags\"]:\n",
    "            if not (x is None):\n",
    "                res_art.append(int(x))\n",
    "        rex[\"tags\"] = res_art\n",
    "\n",
    "        return rex\n",
    "\n",
    "    # Gen new results according to the truth and users output\n",
    "    def gen_new_result(self, result, truth, label):\n",
    "\n",
    "        s1 = set()\n",
    "        for tag in label:\n",
    "            s1.add(self.tag_dic[tag.replace(' ', '')])\n",
    "        s2 = set()\n",
    "        for name in truth:\n",
    "            s2.add(self.tag_dic[name.replace(' ', '')])\n",
    "\n",
    "        for a in range(0, self.task_cnt):\n",
    "            in1 = (a + 1) in s1\n",
    "            in2 = (a + 1) in s2\n",
    "            if in1:\n",
    "                if in2:\n",
    "                    result[0][a][\"TP\"] += 1\n",
    "                else:\n",
    "                    result[0][a][\"FP\"] += 1\n",
    "            else:\n",
    "                if in2:\n",
    "                    result[0][a][\"FN\"] += 1\n",
    "                else:\n",
    "                    result[0][a][\"TN\"] += 1\n",
    "\n",
    "        return result\n",
    "\n",
    "    # Calculate precision, recall and f1 value\n",
    "    # According to https://github.com/dice-group/gerbil/wiki/Precision,-Recall-and-F1-measure\n",
    "    @staticmethod\n",
    "    def get_value(res):\n",
    "        if res[\"TP\"] == 0:\n",
    "            if res[\"FP\"] == 0 and res[\"FN\"] == 0:\n",
    "                precision = 1.0\n",
    "                recall = 1.0\n",
    "                f1 = 1.0\n",
    "            else:\n",
    "                precision = 0.0\n",
    "                recall = 0.0\n",
    "                f1 = 0.0\n",
    "        else:\n",
    "            precision = 1.0 * res[\"TP\"] / (res[\"TP\"] + res[\"FP\"])\n",
    "            recall = 1.0 * res[\"TP\"] / (res[\"TP\"] + res[\"FN\"])\n",
    "            f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "        return precision, recall, f1\n",
    "\n",
    "    # Generate score\n",
    "    def gen_score(self, arr):\n",
    "        sumf = 0\n",
    "        y = {\"TP\": 0, \"FP\": 0, \"FN\": 0, \"TN\": 0}\n",
    "        for x in arr[0]:\n",
    "            p, r, f = self.get_value(x)\n",
    "            sumf += f\n",
    "            for z in x.keys():\n",
    "                y[z] += x[z]\n",
    "\n",
    "        _, __, f_ = self.get_value(y)\n",
    "\n",
    "        return (f_ + sumf * 1.0 / len(arr[0])) / 2.0\n",
    "\n",
    "    # Test with ground truth path and the user's output path\n",
    "    def test(self, truth_path, output_path):\n",
    "        cnt = 0\n",
    "        result = [[]]\n",
    "        for a in range(0, self.task_cnt):\n",
    "            result[0].append({\"TP\": 0, \"FP\": 0, \"TN\": 0, \"FN\": 0})\n",
    "\n",
    "        with open(truth_path, \"r\", encoding='utf-8') as inf, open(output_path, \"r\", encoding='utf-8') as ouf:\n",
    "            for line in inf:\n",
    "                ground_doc = json.loads(line)\n",
    "                user_doc = json.loads(ouf.readline())\n",
    "                for ind in range(len(ground_doc)):\n",
    "                    ground_truth = ground_doc[ind]['labels']\n",
    "                    user_output = user_doc[ind]['labels']\n",
    "                    cnt += 1\n",
    "                    result = self.gen_new_result(result, ground_truth, user_output)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "# Generatue final_score\n",
    "def get_score(truth_path_labor, output_path_labor, tag_path_labor,\n",
    "              truth_path_divorce, output_path_divorce, tag_path_divorce,\n",
    "              truth_path_loan, output_path_loan, tag_path_loan):\n",
    "    judger_labor = Judger(tag_path=tag_path_labor)\n",
    "    reslt_labor = judger_labor.test(truth_path=truth_path_labor,\n",
    "                                    output_path=output_path_labor)\n",
    "    score_labor = judger_labor.gen_score(reslt_labor)\n",
    "    print('score_labor', score_labor)\n",
    "\n",
    "    judger_divorce = Judger(tag_path=tag_path_divorce)\n",
    "    reslt_divorce = judger_divorce.test(truth_path=truth_path_divorce,\n",
    "                                        output_path=output_path_divorce)\n",
    "    score_divorce = judger_divorce.gen_score(reslt_divorce)\n",
    "    print('score_divorce', score_divorce)\n",
    "\n",
    "    judger_loan = Judger(tag_path=tag_path_loan)\n",
    "    reslt_loan = judger_loan.test(truth_path=truth_path_loan,\n",
    "                                  output_path=output_path_loan)\n",
    "    score_loan = judger_loan.gen_score(reslt_loan)\n",
    "    print('score_loan', score_loan)\n",
    "    \n",
    "    return (score_labor + score_divorce + score_loan) / 3.0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_labor 0.0\n",
      "score_divorce 0.002391185101511123\n",
      "score_loan 0.0\n",
      "0.0007970617005037076\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    final_score = get_score(\n",
    "                            truth_path_labor='labor/data_small_selected.json',\n",
    "                            output_path_labor='output/labor/output.json',\n",
    "                            tag_path_labor='labor/tags.txt',\n",
    "                            truth_path_divorce='divorce/data_small_selected.json',\n",
    "                            output_path_divorce='output/divorce/output.json',\n",
    "                            tag_path_divorce='divorce/tags.txt',\n",
    "                            truth_path_loan='loan/data_small_selected.json',\n",
    "                            output_path_loan='output/loan/output.json',\n",
    "                            tag_path_loan='loan/tags.txt')\n",
    "    print(final_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_labor 0.03426911596830585\n",
      "score_divorce 0.05159578736899335\n",
      "score_loan 0.03806323717853543\n",
      "0.041309380171944875\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    final_score = get_score(\n",
    "                            truth_path_labor='labor/data_small_selected.json',\n",
    "                            output_path_labor='output/ClassifierChain/labor/output.json',\n",
    "                            tag_path_labor='labor/tags.txt',\n",
    "                            truth_path_divorce='divorce/data_small_selected.json',\n",
    "                            output_path_divorce='output/ClassifierChain/divorce/output.json',\n",
    "                            tag_path_divorce='divorce/tags.txt',\n",
    "                            truth_path_loan='loan/data_small_selected.json',\n",
    "                            output_path_loan='output/ClassifierChain/loan/output.json',\n",
    "                            tag_path_loan='loan/tags.txt')\n",
    "    print(final_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
