{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "divorce_model=Doc2Vec.load(\"divorce/divorce.model\")\n",
    "loan_model=Doc2Vec.load(\"loan/loan.model\")\n",
    "labor_model=Doc2Vec.load(\"labor/labor.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = {1: \"divorce/data.txt\", 2: \"labor/data.txt\", 3: \"loan/data.txt\"}\n",
    "models={1:divorce_model,2:loan_model,3:labor_model}\n",
    "data_type = {1: \"divorce\", 2: \"labor\", 3: \"loan\"}\n",
    "label_size = 20\n",
    "test_ratio = 0.3\n",
    "punction = \"！？。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_processing(line):  # 提取每行数据的文本内容\n",
    "    line = line.strip().split('\\t')\n",
    "    sentence = line[1]\n",
    "    sentence = re.sub(r'[{}]'.format(punction),' ',sentence).split(' ')\n",
    "    sent=[]\n",
    "    for sub_sentence in sentence:\n",
    "        sent.extend(list(jieba.cut(sub_sentence)))\n",
    "    return line[0], sent, line[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructDataSet(data_path,model_tag): #构建X，Y的数据集\n",
    "    data_file = open(data_path,'r',encoding='utf-8')\n",
    "    lines = data_file.read().splitlines()\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    d2v = models[model_tag]\n",
    "    for line in lines:\n",
    "        _,x,y = line_processing(line)\n",
    "        x=d2v.infer_vector(x)\n",
    "        X.append(x)\n",
    "        y = list(map(int,y.split()))\n",
    "        Y.append(y)\n",
    "    Y = np.array(Y).transpose()\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(X,Y): #构建训练集和测试集\n",
    "    X_train,X_test,Y_train,Y_test =  train_test_split(X,Y,test_size=test_ratio,shuffle=True)\n",
    "    return X_train,X_test,Y_train,Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSVM(X,Y,model_path): #训练单个分类器\n",
    "    X_train,X_test,Y_train,Y_test = splitDataSet(X,Y)\n",
    "    classifier = SVC(gamma='auto')\n",
    "    classifier.fit(X_train,Y_train)\n",
    "    accuracy = classifier.score(X_test,Y_test)\n",
    "    joblib.dump(classifier,model_path)\n",
    "    print(model_path,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beginTrain():\n",
    "    for i in range(1,4):\n",
    "        print(data_input[i].split(\"/\")[0])\n",
    "        X,Y = constructDataSet(data_input[i],i)\n",
    "        tag = list(range(len(Y)))\n",
    "        random.shuffle(tag)\n",
    "        for j in tag:\n",
    "            model_path = data_input[i].split(\"/\")[0]+'/'+str(j+1)+\".model\"\n",
    "            print(model_path)\n",
    "            trainSVM(X,Y[j],model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSingleLabel(x,model_type,label_tag):\n",
    "    model_path = model_type+'/'+'label'+str(label_tag+1)+'.model'\n",
    "    model = joblib.load(model_path)\n",
    "    return model.predict([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text,model_type):\n",
    "    text = re.sub(r'[{}]'.format(punction),' ',text).split(' ')\n",
    "    words=[]\n",
    "    for word in text:\n",
    "        words.extend(list(jieba.cut(word)))\n",
    "    d2v = models[model_type]\n",
    "    x = d2v.infer_vector(words)\n",
    "    res=[]\n",
    "    for i in range(label_size):\n",
    "        res.append(predictSingleLabel(x,data_type[model_type],i)[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"婚生子付某乙由原告抚养，被告每月支付抚养费800元，学费和医疗费凭票各承担一半；\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(text,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
